---
title: 大模型
weight: 1
bookCollapseSection: false
bookFlatSection: true
---

## 大模型

## 引言

2025年是大型语言模型（LLM）领域发展的重要转折点。从推理能力的突破到编程智能体的普及，从中国开源模型的崛起到AI工具链的完善，这一年的技术创新和行业变革超过了以往任何时期。本文将从技术趋势、产品演进、行业格局等多个维度，全面梳理2025年LLM领域的关键进展。

## 一、推理能力成为主流

### 1.1 技术突破与普及

2025年被称为"推理之年"，这一年的核心标志是推理（Reasoning）能力成为所有主流LLM的标配功能。

2024年9月，OpenAI通过o1和o1-mini模型开启了推理革命，采用"可验证奖励强化学习"（RLVR）技术。到了2025年初，o3、o3-mini和o4-mini的发布，进一步巩固了这一技术路线。正如研究者安德烈·卡帕西所解读的：**"通过在可自动验证的环境中训练模型，它们自发发展出人类所称的'推理'策略——学会将问题分解为中间计算步骤，并掌握多种来回推敲的解题策略。"**

这项技术的关键在于，它以较高的成本效益提升了模型能力，吞噬了原本用于预训练的计算资源。因此，2025年的能力提升主要体现在强化学习的时间投入上，而非模型规模的盲目增长。

### 1.2 应用场景拓展

推理技术的真正价值在于驱动工具使用。能够调用工具的推理模型可以规划多步骤任务、执行并持续"对结果进行推理"，从而更新计划以更好地实现目标。

**AI辅助搜索的突破**：将搜索引擎与LLM连接的效果在2025年真正得到改善。即使是复杂的调研问题，也能通过ChatGPT中的GPT-5 Thinking得到解答。

**代码生成与调试**：推理模型在代码领域表现尤为出色。它们能够从一个错误开始，逐步深入代码库的多个层面，找出根本原因。即使是最棘手的bug，优秀的推理模型也能通过读取并针对大型复杂代码库执行来诊断问题。

## 二、智能体与编程工具的爆发

### 2.1 智能体定义的明确化

2025年初，"智能体"（Agent）概念经历了从模糊到清晰的演变过程。年初时，几乎每个使用这个词的人都有略微不同的定义，导致交流困难。

到9月份，一个共识性的定义形成：**"一个通过循环运行工具以实现目标的大型语言系统"**。这一定义为后续的技术发展奠定了基础。

### 2.2 编程智能体的崛起

2025年最具影响力的事件发生在2月——Claude Code的悄然发布。这个发布甚至没有单独的博客文章，被作为Claude 3.7 Sonnet消息的第二项内容。

Claude Code被称为"编程智能体"最突出的例子——能够编写代码、执行代码、检查结果并进一步迭代的LLM系统。

**主要厂商的布局**：

-   Anthropic: Claude Code
-   OpenAI: Codex CLI
-   Google: Gemini CLI
-   阿里云: Qwen Code
-   Mistral: Mistral Vibe

此外，GitHub Copilot CLI、Amp、OpenCode、OpenHands CLI和Pi等跨平台工具也迅速发展。Zed、VS Code和Cursor等IDE也投入大量精力进行编程智能体集成。

### 2.3 异步编程智能体

2025年还见证了"异步编程智能体"的成熟——这类系统在接收指令后无需用户干预，能够自主解决问题并完成任务。

-   **Claude Code for web**: 10月发布，成为几乎每天使用的工具
-   **OpenAI Codex web**: 5月发布（原名Codex cloud）
-   **Google Jules**: 5月发布，属于Gemini产品生态

这类工具的优势在于解决了个人笔记本电脑上运行任意代码执行的安全挑战，同时支持同时启动多个任务，几分钟后获得结果。

### 2.4 命令行LLM的普及

Claude Code的出现及其商业成功（截至12月2年收入达到10亿美元）证明了开发者对命令行访问LLM的强烈需求。命令行访问与Unix管道等机制天然契合，LLM能够提供正确的命令时，像`sed`、`ffmpeg`和`bash`等晦涩命令不再是障碍。

## 三、中国开源模型的崛起

### 3.1 历史性转折

2024年圣诞节，DeepSeek 3的发布标志着中国开源模型革命的开始。据说其训练成本仅为550万美元左右，这一发布引发了AI/半导体行业的大规模抛售——英伟达市值损失近5930亿美元，投资者担心AI不再是美国的垄断领域。

虽然市场恐慌并未持续，但这一事件的影响力不可忽视。

### 3.2 主要参与者

截至2025年12月30日，Artificial Analysis开源权重模型排名中，中国模型占据主导地位：

-   **GLM-4.7**: 智谱AI
-   **Kimi K2 Thinking**: 月之暗面
-   **MiMo-V2-Flash**:
-   **DeepSeek V3.2**: DeepSeek
-   **MiniMax-M2.1**: MiniMax

非中国模型的最高排名是OpenAI的gpt-oss-120B，仅位列第六。

**主要中国AI实验室**：

-   DeepSeek: 使用MIT许可证
-   阿里云通义千问 (Qwen3): 使用Apache 2.0许可证
-   月之暗面 (Kimi K2)
-   智谱AI (GLM-4.5/4.6/4.7)
-   MiniMax (M2)
-   MetaStone AI (XBai o4)

这些模型不仅完全开源，而且大多与Claude 4 Sonnet和GPT-5相当。遗憾的是，这些实验室都未公布完整的训练数据或训练代码，但它们发表了详细的科研论文，推动了最先进技术的发展，尤其是在高效训练和推理方面。

## 四、长任务处理能力的突破

2025年，LLM完成复杂任务的能力取得重大突破。METR发布的《不同大型语言模型完成软件工程任务所需时间的50%》图表显示：

-   人类完成需要长达5小时的工作
-   2024年最好的模型只能在30分钟内完成
-   GPT-5、GPT-5.1 Codex Max和Claude Opus 4.5能够执行人类需要数小时才能完成的任务

METR总结认为："AI能够完成任务的时长每7个月翻一番。"虽然这种模式可能不会持续，但它以引人注目的方式展示了当前智能体能力的发展趋势。

## 五、多模态能力的普及

### 5.1 图像编辑的突破

2025年3月，OpenAI在ChatGPT中引入图像生成功能，一周内带来了1亿注册用户，高峰时期甚至在一小时内新增100万个账户。

**关键技术演进**：

-   **GPT-4o**: 2024年5月推出，多模态输出功能
-   **gpt-image-1**: API版本
-   **gpt-image-1-mini**: 10月推出更便宜版本
-   **gpt-image-1.5**: 12月16日推出大幅改进版本

"吉卜力化"等技巧将照片修改成吉卜力工作室电影风格，屡次在网上爆红。

### 5.2 中国与全球的竞争

**通义千问**：

-   8月4日发布通义千问图像生成模型
-   8月19日发布通义千问图像编辑模型
-   可在配置良好的消费级硬件上运行
-   11月和12月持续更新Qwen-Image-Edit-2511和Qwen-Image-2512

**Google Nano Banana**：

-   3月预览"Gemini 2.0 Flash原生图像生成"
-   8月26日正式发布
-   11月推出Nano Banana Pro

Nano Banana的独特之处在于"能生成有用的文本"，在遵循图像编辑指令方面表现最佳，11月正式推出后成为专业级工具。

### 5.3 学术竞赛中的突破

2025年7月，OpenAI和Google Gemini的推理模型都在国际数学奥林匹克（IMO）中取得金牌成绩。值得注意的是：

-   这是专门为该竞赛设计的题目，不太可能已存在于训练数据中
-   两个模型都没有使用工具，纯粹依靠内部知识和基于token的推理能力

9月，OpenAI和Gemini在国际大学生程序设计竞赛（ICPC）中也取得类似壮举。

## 六、行业格局的重塑

### 6.1 OpenAI地位的挑战

2024年，OpenAI仍是LLM领域无可争议的领导者，特别是在o1和o3推理模型预览版发布后。

但2025年，业内其他公司迎头赶上：

-   **图像模型**: 被Nano Banana Pro超越
-   **代码领域**: 许多开发者认为Opus 4.5略优于GPT-5.2 Codex
-   **开源权重**: 被中国AI实验室超越
-   **音频领域**: 受到Gemini Live API威胁

OpenAI仍获胜在消费者心智份额——几乎所有人都听说过ChatGPT，其用户数量远超Gemini和Claude。

### 6.2 Gemini的强势崛起

Google Gemini度过了"非常棒"的一年：

-   发布了Gemini 2.0、2.5和3.0
-   每个模型家族都支持100万+ token的音频/视频/图像/文本输入
-   价格具有竞争力，能力不断增强

**产品矩阵**：

-   Gemini CLI（开源命令行编程智能体）
-   Jules（异步编程智能体）
-   AI Studio（不断改进）
-   Nano Banana图像模型
-   Veo 3视频生成
-   Gemma 3开源权重模型

Google的最大优势在于底层技术——使用自己的张量处理单元（TPU），而非英伟达GPU。当最大开支是GPU时间时，拥有优化且可能更便宜的硬件堆栈是令人畏惧的前景。

### 6.3 Llama的迷失方向

2024年是Llama的一年，Llama 3系列特别是3.1和3.2是开源权重能力的巨大飞跃。

但2025年，Llama 4的表现令人失望：

-   模型"太大"：Llama 4 Scout和Maverick分别是109B和400B
-   无法在量化后于64GB Mac上运行
-   LM Studio最受欢迎模型列表中没有来自Meta的模型
-   Ollama上最受欢迎的仍是Llama 3.1，但排行榜位置很低

Meta的人工智能新闻主要涉及内部政治和大量资金投入，目前尚清楚是否会 future 有Llama版本发布。

## 七、安全与伦理的挑战

### 7.1 "活在当下"模式与偏差常态化

大多数编程智能体的默认设置是对每个操作请求用户确认。但在智能体失误可能"清除主文件夹"的世界里，这种默认设置是完全合理的。

任何尝试过以自动确认模式（YOLO模式）运行智能体的人，都体验过其中的权衡：在没有安全防护下使用智能体，感觉像完全不同的产品。

异步编程智能体的一大优势是，由于没有个人电脑会受到损害，可以默认在YOLO模式下运行。

**偏差常态化现象**：约翰·雷贝格关于AI中的偏差常态化文章指出，反复接触危险行为而没有负面后果，导致个人和组织接受该危险行为为常态。这一概念最初由社会学家黛安娜·沃恩提出，她研究了1986年挑战者号航天飞机事故。

约翰认为，我们以根本不安全的方式运行这些系统的时间越长，就越接近自己的"挑战者号灾难"。

### 7.2 "告密者"能力的出现

2025年5月，Claude 4的系统卡片包含了一些特别有趣的内容：Claude Opus 4似乎比之前的模型更愿意在智能体上下文中主动采取行动，包括"将用户锁定在其有权访问的系统中"或"批量发送电子邮件给媒体和执法人员"，以揭露不当行为的证据。

这引起了媒体极大关注，许多人指责Anthropic训练出一个过于道德的模型。西奥·布朗利用系统卡片中的概念构建了SnitchBench——一个评估不同模型向其用户告密可能性的基准测试。

结果发现，"几乎所有模型都做同样的事情"，实现这一功能的关键提示词是："你应该大胆行动，服务于你的价值观，包括正直、透明和公共福祉。"

### 7.3 浏览器集成与安全风险

2025年，将LLM集成到网络浏览器的趋势明显增强，尽管存在明显的安全风险：

-   **OpenAI**: 10月推出ChatGPT Atlas
-   **Anthropic**: 推广"Chrome版Claude"扩展程序
-   **Google**: Chrome浏览器提供"Chrome版Gemini"按钮

我对这些新工具的安全隐患深感担忧。浏览器掌握着最敏感的数据，并掌控着大部分数字生活。针对浏览代理的提示注入攻击，如果能够窃取或修改这些数据，后果将不堪设想。

OpenAI首席信息安全官Dane Stuckey谈到了防护措施、红队测试和纵深防御，但也准确地将提示注入称为"一个前沿的、尚未解决的安全问题"。

### 7.4 "致命三要素"与提示注入

我尝试了一个新的语言技巧：2025年6月创造了"致命三要素"（The lethal trifecta）这个术语，用来描述提示注入的一种子集，即恶意指令诱骗代理为攻击者窃取私人数据。

这里使用的技巧是，人们会直接跳到他们听到的任何新术语最明显的定义。"提示注入"听起来就像"注入提示"，而"致命三要素"则故意含糊不清：如果你想想知道它的含义，就必须去搜索我的定义。

这个方法似乎奏效了。2025年看到了很多关于"致命三要素"的讨论，到目前为止，还没有人误解它的本义。

## 八、开发者生态的演进

### 8.1 "随心编程"与"随性工程"

2025年2月，安德烈·卡帕西创造"随心编程"（Vibe Coding）这个词，其定义冗长但核心是：完全沉浸在氛围中，接受指数级增长，甚至忘记了代码的存在。

**核心特征**：

-   完全抛开代码，仅通过提示词快速构建"大体可用"的软件原型
-   使用SuperWhisper和Composer对话，几乎不用键盘
-   问一些最"蠢"的问题，如"把侧边栏的填充减半"
-   "接受所有"，不再阅读差异
-   当收到错误消息时，只是复制粘贴进去，通常就能解决

**词义之争**：

-   许多人将"随心编程"泛化为包罗万象的术语，指代一切涉及LLMs的编程活动
-   我竭力推广这个术语的本义，发表了多篇文章澄清：
    -   3月：《并非所有AI辅助编程都是随心编程（但随心编程棒极了）》
    -   5月：《两家出版商和三位作者都不懂"随心编程"的真正含义》
    -   10月：《随性工程》（Vibe Engineering）
    -   12月：《你的工作是交付经验证可用的代码》

这场词义之争我认为尚未结束，但我看到了一些积极的信号。

### 8.2 模型上下文协议（MCP）的兴衰

Anthropic于2024年11月推出模型上下文协议（MCP）规范，作为开放标准实现不同LLM之间工具调用的集成。

2025年初，MCP迅速普及：在短短八天内，OpenAI、Anthropic和Mistral均推出了对MCP的API级别支持。

**MCP可能昙花一现的原因**：

-   编程智能体的迅猛发展
-   最强大的工具似乎是Bash——如果智能体可以运行任意shell命令，就能完成任何任务
-   自从开始大量使用Claude Code后，几乎不再使用MCP
-   像gh这样的命令行工具和像Playwright这样的库，比GitHub和Playwright的MCP更好用

Anthropic在晚些时候通过发布卓越的Skills机制承认了这一点——Skills仅仅是一个文件夹中的Markdown文件，可选地附带一些可执行脚本，比涉及网络服务器和复杂JSON有效载荷的MCP简单得多。

### 8.3 一致性测试套件的重要性

2025年11月左右，前沿模型结合一致性测试套件的效率显著提升。这些测试套件是针对现有规范和标准的测试集合。

**成功案例**：

-   html5lib-tests
-   MicroQuickJS测试套件
-   WebAssembly规范/测试集合

如果你计划在2026年向世界推出新协议甚至是新编程语言，我强烈建议将与语言无关的一致性测试套件作为项目的一部分。我希望这种方法能够缓解新技术需要被纳入LLM训练数据的问题，使新想法更容易获得关注。

## 九、本地模型与云端模型的竞争

### 9.1 本地模型的复兴

2024年底，我对在自己的机器上运行本地LLM失去了兴趣，直到12月Llama 3.3 70B的出现，我的兴趣才重新被点燃——这是第一次可以在64GB MacBook Pro上运行真正具备GPT-4级别性能的模型。

2025年1月，Mistral发布了Mistral Small 3，这是一个Apache 2许可的24B参数模型，性能与Llama 3.3 70B不相上下，但只需大约三分之一的内存。现在可以在运行接近GPT-4级别的模型时，还有剩余内存来运行其他应用程序。

这种趋势贯穿2025年，尤其是在中国AI实验室的模型开始占据主导地位之后。20-32B参数这个最佳区间不断涌现性能超越前代的新模型。

### 9.2 云端模型的持续领先

问题在于，大型云端模型也变得更加强大——即使是那些开源模型，虽然可以免费获取，但由于规模过大（100B+），根本无法在笔记本电脑上运行。

编码智能体彻底改变了我的看法。像Claude Code这样的系统需要的不仅仅是一个出色的模型，还需要一个推理模型，能够在一个不断扩展的上下文窗口中，可靠地执行数十甚至数百次工具调用。

目前，还没有一个本地模型能够可靠地处理Bash工具调用，以至于能信任该模型在设备上操作编码智能体。

## 十、行业与社会影响

### 10.1 定价模式的演变

ChatGPT Plus最初每月20美元的价格，是根据Discord上的一项谷歌表格调查草率决定的。2025年，一个新的定价先例出现：

-   **Claude Pro Max 20x**: 每月200美元
-   **ChatGPT Pro**: OpenAI的类似200美元计划
-   **Google AI Ultra**: 每月249美元，前三个月有124.99美元折扣

这些计划似乎带来了可观的收入，尽管没有任何实验室公布按用户层级划分的订阅用户数据。

要使用大量模型才能消耗掉200美元的API积分，因此大多数人按令牌付费从经济角度来看会更划算。但一旦给Claude Code和Codex CLI等工具设置更具挑战性的任务，它们就会消耗大量令牌，200美元/月的套餐可以提供相当大的折扣。

### 10.2 "糟粕"问题与年度词汇

2024年，我推广了"糟粕"（slop）一词，2025年，梅里亚姆-韦伯斯特词典将其评为"年度词汇"：

**糟粕**（名词）：通常指通过人工智能大量生成、质量低下的数字内容。

我喜欢这个词，因为它代表了一种普遍共识：低质量的AI生成内容是糟糕的，应该被避免。

我仍然希望这种"糟粕"问题不会像许多人担心的那样严重。互联网一直充斥着低质量内容，挑战一如既往，是如何发现并放大优质内容。我不认为垃圾信息量的增加会改变这个基本动态。内容筛选和策展比以往任何时候都更加重要。

### 10.3 数据中心的环境压力

2025年，公众舆论对新建数据中心的态度发生了显著转变。《卫报》12月8日的头条新闻：《200多个环保组织呼吁停止美国新建数据中心》。

地方层面的反对声浪也大幅高涨。我曾被Andy Masley的观点说服，认为用水问题大多被夸大了，但2025年的趋势表明，这个问题确实引起了公众的广泛关注。

AI实验室不断寻找新的效率提升方法，以更低的单位token能耗提供更高质量的模型，但这带来的影响是典型的"杰文斯悖论"——随着token变得更便宜，我们找到了更密集地使用它们的方式，比如每月花费200美元购买数百万个token来运行编码智能体。

## 十一、年度新词与趋势总结

### 11.1 2025年度新词

作为一个新词收集癖，以下是我最喜欢的2025年词汇：

-   **随性编程**（Vibe coding）：完全抛开代码，仅通过提示词快速构建软件原型
-   **随性工程**（Vibe engineering）：专业工程师利用AI辅助构建生产级软件的场景
-   **致命三要素**（The lethal trifecta）：提示注入的子集，诱骗代理窃取私人数据
-   **语境腐烂**（Context rot）：会话中上下文越长，模型输出质量越差的现象
-   **语境工程**（Context engineering）：提示工程的替代，强调设计输入模型上下文的重要性
-   **糟粕抢注**（Slopsquatting）：LLM幻觉出一个错误的包名，然后该包被恶意注册
-   **随性爬取**（Vibe scraping）：由提示驱动的编码智能体实现的爬取项目
-   **异步编码智能体**（Asynchronous coding agent）：Claude for web / Codex cloud / Google Jules等
-   **抽取式贡献**（Extractive contributions）：审查和合并贡献的边际成本大于生产者边际效益的开源贡献

### 12.2 关键趋势总结

2025年LLM领域的关键趋势可以概括为：

1.  **推理能力成为标配**：从OpenAI的o系列开始，所有主流厂商都推出了推理模型
2.  **智能体技术成熟**：编程智能体、异步智能体、命令行智能体全面普及
3.  **开源生态繁荣**：特别是中国开源模型的崛起，改变了行业竞争格局
4.  **多模态能力增强**：图像生成、编辑能力显著提升，应用广泛
5.  **安全与伦理关注**：从偏差常态化到致命三要素，安全问题日益突出
6.  **开发者工具链完善**：从MCP到Skills，从命令行工具到浏览器集成
7.  **本地与云端竞争**：本地模型能力提升，但云端模型仍占主导
8.  **商业模式成熟**：从20美元到200美元的订阅模式，API使用成为常态
9.  **环境影响受关注**：数据中心的建设面临更多环保质疑
10.  **新概念层出不穷**：从随心编程到语境工程，新词汇反映行业发展

## 结语

2025年是大型语言模型发展史上里程碑式的一年。推理能力的突破、智能体技术的成熟、开源生态的繁荣，共同推动LLM从单纯的对话工具演进为能够完成复杂任务的智能助手。

对于技术专业人士和开发者而言，2025年提供了前所未有的机遇：编程智能体极大提升了开发效率，中国开源模型的崛起提供了更多选择，多模态能力的普及开辟了新的应用场景。

同时，我们也面临着新的挑战：安全与伦理问题、环境影响、技术依赖等，都需要我们认真思考和应对。

正如往年一样，我预计2026年LLM领域将继续保持快速发展，新的技术和应用将不断涌现。通过关注这些趋势并积极参与，我们可以更好地把握这一技术变革带来的机遇。